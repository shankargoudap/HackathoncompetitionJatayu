{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant Disease MobileNetV2 .ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCl6gs2YZxNm"
      },
      "source": [
        "##UPDATES\n",
        "\n",
        "***09/04/2021*** : Reorganized code.\n",
        "\n",
        "***10/04/2021*** : Added callbacks in the model.fit function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBgTorMQaRnB"
      },
      "source": [
        "##Purpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7cK2oW8mr_k"
      },
      "source": [
        "  In this notebook we create & train a N.N. model with **transfer learning based on DenseNet169**.\n",
        "\n",
        "  The purpose of of the model is to classify plant's leaf images and extract decisions regarding their health.\n",
        "\n",
        "  It is able to classify **38 different classes** ,13 different plants and some diseases that harm them .\n",
        "\n",
        "  The Model is on it's own very light , but we are still going to convert it into a TF Lite version  in order to **run inference on a portable device , a RaspBerry Pi 4B** ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ5Vuo6Xk96o"
      },
      "source": [
        "###Libraries and modules imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlmLBbVuyCD-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "from google.colab import files\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import DenseNet169 #57 MB acc Top1 0.762 top5 0.932\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D , Dropout"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCCb17VWwP7r"
      },
      "source": [
        "###Import a kaggle dataset directly to google colab (be wise with your time !)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHTJtv3et0yn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "9e8292d9-738a-4fae-afdc-175b24d3e397"
      },
      "source": [
        "####### SCRIPT TO DOWNLOAD KAGGLE DATASET IN GOOGLE COLAB ######### .\n",
        "from google.colab import files\n",
        "#Upload your kaggle.json file\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p  ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "#Copy the API command from kaggle .\n",
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset\n",
        "\n",
        "#Unzip dataset ,always with -q (quiet)\n",
        "!unzip -q /content/new-plant-diseases-dataset.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2b6a5679-cfac-40e0-a959-d6fa06ece24f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2b6a5679-cfac-40e0-a959-d6fa06ece24f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-83245b7d3ab5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Upload your kaggle.json file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir -p  ~/.kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTUw9StOmizy"
      },
      "source": [
        "###Auxiliar Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nca7eFJCDe_R"
      },
      "source": [
        "#Necessary data preparation.\n",
        "def data_prep():\n",
        "    #Apply data augmentation on-the-fly on the training set to increase generalizability of the model.\n",
        "    train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255,\n",
        "                                                                shear_range = 0.2,\n",
        "                                                                zoom_range = 0.2,\n",
        "                                                                width_shift_range = 0.2,\n",
        "                                                                height_shift_range = 0.2,\n",
        "                                                                fill_mode=\"nearest\")\n",
        "    #Create the pipeline\n",
        "    train_data = train_datagen.flow_from_directory(os.path.join(PATH,\"train\"),\n",
        "                                                  target_size=(image_size,image_size),\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  class_mode=\"categorical\")\n",
        "    # Normalize validation dataset's image rgb values.\n",
        "    valid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255)\n",
        "    #Create the pipeline\n",
        "    valid_data = valid_datagen.flow_from_directory(os.path.join(PATH,\"valid\"),\n",
        "                                                  target_size=(image_size,image_size),\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  class_mode=\"categorical\")\n",
        "    return[train_data,valid_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XaVoTZ7xFfw"
      },
      "source": [
        "#Plot training learning curves for both train and validation.\n",
        "def plot_training_curves(history):\n",
        "        #Defining the metrics we will plot.\n",
        "        train_acc=history.history['accuracy']\n",
        "        val_acc=history.history['val_accuracy']\n",
        "        train_loss = history.history['loss']\n",
        "        val_loss = history.history['val_loss']\n",
        "\n",
        "        #Range for the X axis.\n",
        "        epochs = range(len(train_loss))\n",
        "\n",
        "        fig,axis=plt.subplots(1,2,figsize=(20,8))#1 row, 2 col , width=20,height=8 inches.\n",
        "\n",
        "        #Plotting Loss figures.\n",
        "        plt.rcParams.update({'font.size': 22}) #configuring font size.\n",
        "        plt.subplot(1,2,1) #plot 1st curve.\n",
        "        plt.plot(epochs,train_loss,c=\"red\",label=\"Training Loss\") #plotting\n",
        "        plt.plot(epochs,val_loss,c=\"blue\",label=\"Validation Loss\")\n",
        "        plt.xlabel(\"Epochs\") #title for x axis\n",
        "        plt.ylabel(\"Loss\")   #title for y axis\n",
        "        plt.legend()\n",
        "\n",
        "        #Plotting Accuracy figures.\n",
        "        plt.subplot(1,2,2) #plot 2nd curve.\n",
        "        plt.plot(epochs,train_acc,c=\"red\",label=\"Training Acc\") #plotting\n",
        "        plt.plot(epochs,val_acc,c=\"blue\",label=\"Validation Acc\")\n",
        "        plt.xlabel(\"Epochs\")   #title for x axis\n",
        "        plt.ylabel(\"Accuracy\") #title for y axis\n",
        "        plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQc75Bz5GDwr"
      },
      "source": [
        "#Make predictions on manually created test dataset folder. (OPTIONAL, different to initial dataset test set)\n",
        "def test_model(path):\n",
        "    i=0\n",
        "    #Inversing class dictionary [keys,values]->[values,keys]\n",
        "    labels = (train_data.class_indices)\n",
        "    labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "    for filename in os.listdir(path) :\n",
        "        i+=1\n",
        "        file_path= path +\"/\" + str(pathlib.Path(filename))\n",
        "\n",
        "        image = tf.keras.preprocessing.image.load_img(\n",
        "                file_path,grayscale=False, color_mode=\"rgb\",\n",
        "                target_size=(image_size,image_size), interpolation=\"nearest\")\n",
        "        input_arr = keras.preprocessing.image.img_to_array(image)\n",
        "        input_arr=input_arr/255\n",
        "        input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
        "        prediction = model.predict(input_arr)\n",
        "\n",
        "\n",
        "        a=np.argmax(prediction)\n",
        "        results = labels[a]\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "      # print(\"Predicted class number :\", np.argmax(prediction))\n",
        "        print(\"Actual class :\" ,pathlib.Path(filename))\n",
        "        print(\"predicted class name->  MobileV2:\",results )\n",
        "\n",
        "\n",
        "    print(\"\\n Tested: \" ,i, \"new unseen images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lELupQFqOud"
      },
      "source": [
        "def assign_callbacks(weights_file,patience,lr_factor):\n",
        "  return[\n",
        "      #Only save the weights that correspond to the minimum validation loss.\n",
        "      tf.keras.callbacks.ModelCheckpoint(filepath=weights_file,\n",
        "                                         monitor='val_accuracy',\n",
        "                                         mode='max',\n",
        "                                         save_best_only=True ,\n",
        "                                         save_weights_only=True,\n",
        "                                         verbose=0),\n",
        "      #If val_loss doesn't improve for a number of epochs set with 'patience'\n",
        "      #variable, training will stop to avoid overfitting.\n",
        "      tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                       mode='min',\n",
        "                                       patience=patience,\n",
        "                                       verbose=1),\n",
        "      #Learning rate is reduced by 'lr_factor' if val_loss stagnates\n",
        "      #for a number of epochs set with 'patience/2' variable.\n",
        "      tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                           mode='min',\n",
        "                                           factor=lr_factor,\n",
        "                                           patience=patience//2,\n",
        "                                           min_lr=1e-6,\n",
        "                                           verbose=1)]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0CZurrvoS__"
      },
      "source": [
        "##Experimental parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W14LSIAClw5"
      },
      "source": [
        "EPOCHS=100 #Number of epochs to train the model.\n",
        "BATCH_SIZE =32\n",
        "PATIENCE=EPOCHS//5\n",
        "LR_FACTOR=0.2\n",
        "WEIGHTS_FILE = \"weights.h5\" #File that stores updated weights\n",
        "image_size =224 #needs to comply with CNN input constraints.\n",
        "PATH=\"/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\" #Path to dataset\n",
        "TEST_PATH='/content/test/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_LrC6IwFZuh"
      },
      "source": [
        "#The training class names.\n",
        "class_names=[\"Apple___Apple_scab\",\"Apple___Black_rot\",\"Apple___Cedar_apple_rust\",\"Apple___healthy\",\n",
        "             \"Blueberry___healthy\",\"Cherry_(including_sour)__Powedery_mildew\",\"Cherry_(including_sour)__healthy\",\n",
        "             \"Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\",\"Corn_(maize)___Common_rust_\",\"Corn_(maize)___Northern_Leaf_Blight\",\n",
        "             \"Corn_(maize)___healthy\",\"Grape___Black_rot\",\"Grape___Esca_(Black_Measles)\",\"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
        "             \"Grape___healthy\",\"Orange___Haunglongbing_(Citrus_greening)\",\"Peach___Bacterial_spot\",\"Peach___healthy\",\n",
        "             \"Pepper,_bell___Bacterial_spot\",\"Pepper,_bell___healthy\",\"Potato___Early_blight\",\"Potato___Late_blight\",\n",
        "             \"Potato___healthy\",\"Raspberry___healthy\",\"Soybean___healthy\",\"Squash___Powdery_mildew\",\n",
        "             \"Strawberry___Leaf_scorch\",\"Strawberry___Healthy\",\"Tomato___Bacterial_spot\",\"Tomato___Early_blight\",\"Tomato___Late_blight\",\n",
        "             \"Tomato___Leaf_Mold\",\"Tomato___Septoria_leaf_spot\",\"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
        "             \"Tomato___Target_Spot\",\"Tomato_Yellow_Leaf_Curl_Virus\",\"Tomato_mosaic_virus\",\"Tomato___healthy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvFqB3gDo4Eu"
      },
      "source": [
        "##Define the Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d-xPccYHcRD"
      },
      "source": [
        "#Create the whole neural network, pass the base model as parameter.\n",
        "def create_model(base_model):\n",
        "      x = base_model.output\n",
        "      #Add a global spatial average pooling layer.\n",
        "      x = GlobalAveragePooling2D()(x)\n",
        "      #Add a fully-connected layer.\n",
        "      x = Dense(1024, activation='relu')(x)\n",
        "      #Add a dropout layer to decrease overfitting\n",
        "      x=Dropout(0.2)(x)\n",
        "      #Add a logistic layer with number_of_neurons=number_of_training_classes.\n",
        "      predictions = Dense(38, activation='softmax')(x)\n",
        "\n",
        "      #This is the model we will train\n",
        "      model = Model(inputs=base_model.input, outputs=predictions\n",
        "                                      ,name=\"Plant_Disease_Detector\")\n",
        "\n",
        "      #Freeze layers of the base model, we will only train the extra layers.\n",
        "      #This way features already learned by the base model aren't lost.\n",
        "      for layer in base_model.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "      #Assign a base learning rate for the Adam optimizer.\n",
        "      base_learning_rate = 0.001\n",
        "      model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate)\n",
        "                    ,loss='categorical_crossentropy' ,metrics='accuracy')\n",
        "\n",
        "      return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-G57hf_vIDU"
      },
      "source": [
        "###Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doekGxu5vMKo"
      },
      "source": [
        "#Prepare data\n",
        "train_data,valid_data=data_prep()\n",
        "#Define callbacks for training\n",
        "callbacks=assign_callbacks(WEIGHTS_FILE,PATIENCE,LR_FACTOR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QCpGsetmS3K"
      },
      "source": [
        "#Create the base pre-trained model, without the classification layers.\n",
        "base_model =DenseNet169(weights='imagenet',\n",
        "                        include_top=False ,input_shape=(224,224,3))\n",
        "#Create the complete new model.\n",
        "model=create_model(base_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4S9GsGaqn7y"
      },
      "source": [
        "#Information about the model's layers.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywWvIHeypzi9"
      },
      "source": [
        "#Train the model on the dataset.\n",
        "history=model.fit(x=train_data , batch_size=BATCH_SIZE,\n",
        "                 epochs=EPOCHS , verbose=2 ,\n",
        "                 validation_data=valid_data,\n",
        "                 steps_per_epoch=20,\n",
        "                 validation_steps=10,\n",
        "                 callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPdEkxg9SUPM"
      },
      "source": [
        "###Plotting the training curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD6b9MlcReUc"
      },
      "source": [
        "#Plot the Learning Curves from model training.\n",
        "plot_training_curves(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkh45hlHRc4G"
      },
      "source": [
        "###Convert to Tensorflow Lite and Quantize model.\n",
        " Converting the model to it's tensorflow lite equivalent and applying quantization provides better efficiency for the live detection on the Raspberry Pi.\n",
        "\n",
        " **Inference will be faster and it will need less memmory space to store model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxyECzCj7FJE"
      },
      "source": [
        "#Load optimal weights computed during training.\n",
        "model.load_weights(WEIGHTS_FILE)\n",
        "#Convert the model to it's Tensorflow Lite equivalent\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT] ##Quantized\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tfliteQuant', 'wb') as f:\n",
        "  f.write(tflite_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8htl7mExu1Mo"
      },
      "source": [
        "####Scripts to save or restore the whole model. (OPTIONAL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHILUEzxbg7U"
      },
      "source": [
        "#Save the whole model for experimentations.\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/DenseNet169')\n",
        "\n",
        "# my_model directory\n",
        "!ls saved_model\n",
        "# Contains an assets folder, saved_model.pb, and variables folder.\n",
        "!ls saved_model/DenseNet169\n",
        "# Zip it before download (So that you can download the whole directory at once )\n",
        "!zip  -r /content/DenseNet169_In_Zip.zip /content/saved_model\n",
        "print(\"Zip Ready\")\n",
        "# Download it\n",
        "files.download('/content/DenseNet169_In_Zip.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF4cvt-wdg6G"
      },
      "source": [
        "#Restore an uploaded model for experimentations\n",
        "files.upload()\n",
        "\n",
        "!unzip -q /content/saved_model_In_Zip.zip\n",
        "new_model = tf.keras.models.load_model('/content/content/saved_model/MobileNetV2')\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p48cGNbku9TQ"
      },
      "source": [
        "###Evaluate the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3YDoIN3PwlL"
      },
      "source": [
        "#Load optimal weights computed during training.\n",
        "model.load_weights(WEIGHTS_FILE)\n",
        "eval=model.evaluate(valid_data)\n",
        "print(eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hCcVRnFfBcH"
      },
      "source": [
        "#Get predictions on the test_dataset you define with TEST_PATH\n",
        "test_model(TEST_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzJdrP-UjJ4p"
      },
      "source": [
        "###Future Work\n",
        "\n",
        "Try different optimizers ,batch-size, dropout-rates and base learning rate."
      ]
    }
  ]
}